"""–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç—á–µ—Ç–∞ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é"""
import logging
import pandas as pd
from telegram import Update
from telegram.ext import ContextTypes
from .report_store import send_and_store
from collections import Counter

logger = logging.getLogger(__name__)

async def start_schedule_report(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–°–æ–æ–±—â–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π —Ñ–∞–π–ª–∞"""
    if update.callback_query:
        await update.callback_query.edit_message_text(
            "üìÖ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º –≥—Ä—É–ø–ø (–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≥—Ä—É–ø–ø.xlsx).\n"
            "–ë–æ—Ç –ø–æ—Å—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –ø–æ –∫–∞–∂–¥–æ–π –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–µ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã."
        )
    else:
        await update.message.reply_text(
            "üìÖ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º –≥—Ä—É–ø–ø (–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≥—Ä—É–ø–ø.xlsx).\n"
            "–ë–æ—Ç –ø–æ—Å—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –ø–æ –∫–∞–∂–¥–æ–π –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–µ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã."
        )

async def process_schedule_file(update: Update, context: ContextTypes.DEFAULT_TYPE, file_path: str) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ ‚Äî –û–°–¢–ê–í–ò–¢–¨ –¢–û–õ–¨–ö–û –û–î–ù–£ –≠–¢–£ –§–£–ù–ö–¶–ò–Æ"""
    try:
        logger.info("process_schedule_file called for %s", getattr(update.message, 'message_id', 'no-message-id'))
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –ø–æ–º–µ—á–∞–µ–º, —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–¥—ë—Ç
        doc_flag = context.user_data.get('processing_schedule')
        if doc_flag:
            logger.info("Schedule processing already in progress, skipping duplicate call")
            return
        context.user_data['processing_schedule'] = True

        df = pd.read_excel(file_path)

        if '–ì—Ä—É–ø–ø–∞' not in df.columns:
            await update.message.reply_text("‚ùå –í —Ñ–∞–π–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '–ì—Ä—É–ø–ø–∞'. –§–∞–π–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π.")
            return

        content_columns = df.columns[3::2]
        if len(content_columns) == 0:
            await update.message.reply_text("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º –ø–æ –¥–Ω—è–º.")
            return

        groups = df['–ì—Ä—É–ø–ø–∞'].dropna().unique()

        report = "üìÖ *–û—Ç—á–µ—Ç –ø–æ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é*\n\n"
        overall_total = 0

        for group in groups:
            if pd.isna(group) or str(group).strip() == '':
                continue

            group_df = df[df['–ì—Ä—É–ø–ø–∞'] == group]
            disciplines = []

            for col in content_columns:
                for cell in group_df[col]:
                    if pd.notna(cell):
                        cell_str = str(cell)
                        for line in cell_str.split('\n'):
                            if '–ü—Ä–µ–¥–º–µ—Ç:' in line:
                                discipline = line.split('–ü—Ä–µ–¥–º–µ—Ç:', 1)[1].strip()
                                if discipline:
                                    disciplines.append(discipline)

            if not disciplines:
                report += f"*–ì—Ä—É–ø–ø–∞ {group}*: –ù–µ—Ç –∑–∞–Ω—è—Ç–∏–π –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏.\n\n"
                continue

            counts = Counter(disciplines)

            report += f"*–ì—Ä—É–ø–ø–∞ {group}*:\n"
            group_total = 0
            for disc, count in sorted(counts.items(), key=lambda x: x[1], reverse=True):
                report += f"‚Ä¢ {disc}: *{count} –ø–∞—Ä*\n"
                group_total += count
                overall_total += count

            report += f"–í—Å–µ–≥–æ –ø–∞—Ä –≤ –≥—Ä—É–ø–ø–µ: *{group_total}*\n\n"

        if overall_total == 0:
            report += "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–Ω—è—Ç–∏—è—Ö –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ.\n"

        report += f"*–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –ø–æ –≤—Å–µ–º –≥—Ä—É–ø–ø–∞–º: {overall_total}*"

        await send_and_store(update, context, report, parse_mode='Markdown', metadata={'type': 'schedule'})

        # –û—á–∏—Å—Ç–∫–∞ —Ñ–ª–∞–≥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        context.user_data.pop('processing_schedule', None)

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")